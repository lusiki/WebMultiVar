# Provedi klastering
# Napravi matricu udaljenosti
D = 1-S
# Pretvori u objekt
d = as.dist(D)
# Provedi klastering (average-linkage)
cc = hclust(d, method = "average")
# Prikaži dendogramom
plot(cc)
clusters.list = rect.hclust(cc, k = 4, border="blue") # Prilagodi grafikon
knitr::include_graphics("../Foto/madrid.jpeg")
knitr::include_graphics("../Foto/madrid.jpg")
knitr::include_graphics("../Foto/net8.png")
# node-list objekt ima jednu varijablu (kolonu) i sadržava ID oznaku za pripadajući edge
node_list <- tibble(id = 1:4)
node_list
node_list
knitr::include_graphics("../Foto/net10.png")
#  edge-list ima minimalno dvije kolone: kolona izvora čvorova (nodes) i kolona smjernica čvorova
#  edge-list objekt može sadržavati i dodatne atribute (varijable)
edge_list <- tibble(from = c(1, 2, 2, 3, 4), to = c(2, 3, 4, 2, 1))
edge_list
node_list_attr <- node_list %>%
mutate(Spol = c("F","F","M","F","M"))
# node-list objekt ima jednu varijablu (kolonu) i sadržava ID oznaku za pripadajući edge
node_list <- tibble(id = 1:5)
# node-list objekt ima jednu varijablu (kolonu) i sadržava ID oznaku za pripadajući edge
node_list <- tibble(id = 1:5)
node_list
node_list_attr <- node_list %>%
mutate(Spol = c("F","F","M","F","M"))
node_list_attr
g = graph_from_data_frame(edge_list, directed = FALSE, vertices = node_list)
g
knitr::include_graphics("../Foto/net5.png")
knitr::include_graphics("../Foto/net6.png")
# get the adjacency matrix of network g
A = as_adjacency_matrix(g)
A = as_adjacency_matrix(g, attr = "weight")
knitr::include_graphics("../Foto/net5.png")
knitr::include_graphics("../Foto/net9.png")
library(eurostat)
dat <- get_eurostat(id = "tsdtr420", time_format = "num")
query <- search_eurostat("road accidents", type = "table")
View(query)
dat <- get_eurostat(id = "sdg_11_40", time_format = "num")
View(dat)
countries <- c("UK", "SK", "FR", "PL", "ES", "PT")
t1 <- get_eurostat("tsdtr420", filters = list(geo = countries))
t1 <- get_eurostat("sdg_11_40", filters = list(geo = countries))
t1
ggplot(t1, aes(x = time, y = values, color = geo, group = geo, shape = geo)) +
geom_point(size = 4) + geom_line() + theme_bw() +
ggtitle("Road accidents") +
xlab("Year") +
ylab("Victims (n)") +
theme(legend.position = "none") +
ggrepel::geom_label_repel(data = t1 %>%
group_by(geo) %>%
na.omit() %>%
filter(time %in% c(min(time), max(time))), aes(fill = geo, label = geo), color = "white")
library(ggplot2)
ggplot(t1, aes(x = time, y = values, color = geo, group = geo, shape = geo)) +
geom_point(size = 4) + geom_line() + theme_bw() +
ggtitle("Road accidents") +
xlab("Year") +
ylab("Victims (n)") +
theme(legend.position = "none") +
ggrepel::geom_label_repel(data = t1 %>%
group_by(geo) %>%
na.omit() %>%
filter(time %in% c(min(time), max(time))), aes(fill = geo, label = geo), color = "white")
library(tidyverse)
ggplot(t1, aes(x = time, y = values, color = geo, group = geo, shape = geo)) +
geom_point(size = 4) + geom_line() + theme_bw() +
ggtitle("Road accidents") +
xlab("Year") +
ylab("Victims (n)") +
theme(legend.position = "none") +
ggrepel::geom_label_repel(data = t1 %>%
group_by(geo) %>%
na.omit() %>%
filter(time %in% c(min(time), max(time))), aes(fill = geo, label = geo), color = "white")
ggplot(t1, aes(x = time, y = values, color = geo, group = geo, shape = geo)) +
geom_point(size = 4) + geom_line() + theme_bw() +
ggtitle("Road accidents") +
xlab("Year") +
ylab("Victims (n)") +
theme(legend.position = "none") +
ggrepel::geom_label_repel(data = t1 %>%
group_by(geo) %>%
na.omit() %>%
filter(time %in% c(min(time), max(time))), aes(fill = geo, label = geo), color = "white")
ggplot(t1, aes(x = time, y = values, color = geo, group = geo, shape = geo)) +
geom_point(size = 4) + geom_line() + theme_bw() +
ggtitle("Road accidents") +
xlab("Year") +
ylab("Victims (n)") +
theme(legend.position = "none")
get_eurostat("tgs00026", time_format = "raw") %>%
# Subset to year 2005 and NUTS-3 leveld
plyr::filter(time == 2005, nchar(as.character(geo)) == 4) %>%
# Classify the values the variable
dplyr::mutate(cat = cut_to_classes(values)) %>%
# Merge Eurostat data with geodata from Cisco
merge_eurostat_geodata(data = ., geocolumn = "geo", resolution = "60",output_class = "df", all_regions = TRUE) %>%
# Plot the map
gplot(data = ., aes(long, lat, group = group)) +
geom_polygon(aes(fill = cat), colour = alpha("white", 1/2), size = .2) +
scale_fill_manual(values = RColorBrewer::brewer.pal(n = 5, name = "Oranges")) +
labs(title = "Disposable household income") +
coord_map(project = "orthographic", xlim = c(-22, 34), ylim = c(35, 70)) +
theme_minimal() +
guides(fill = guide_legend(title = "EUR per Year",title.position = "top", title.hjust = 0))
get_eurostat("tgs00026", time_format = "raw") %>%
# Subset to year 2005 and NUTS-3 leveld
plyr::filter(time == 2005, nchar(as.character(geo)) == 4) %>%
# Classify the values the variable
dplyr::mutate(cat = cut_to_classes(values)) %>%
# Merge Eurostat data with geodata from Cisco
merge_eurostat_geodata(data = ., geocolumn = "geo", resolution = "60",output_class = "df", all_regions = TRUE) %>%
# Plot the map
ggplot(data = ., aes(long, lat, group = group)) +
geom_polygon(aes(fill = cat), colour = alpha("white", 1/2), size = .2) +
scale_fill_manual(values = RColorBrewer::brewer.pal(n = 5, name = "Oranges")) +
labs(title = "Disposable household income") +
coord_map(project = "orthographic", xlim = c(-22, 34), ylim = c(35, 70)) +
theme_minimal() +
guides(fill = guide_legend(title = "EUR per Year",title.position = "top", title.hjust = 0))
library(eurostat)
get_eurostat("tgs00026", time_format = "raw") %>%
# Subset to year 2005 and NUTS-3 leveld
plyr::filter(time == 2005, nchar(as.character(geo)) == 4) %>%
# Classify the values the variable
dplyr::mutate(cat = cut_to_classes(values)) %>%
# Merge Eurostat data with geodata from Cisco
merge_eurostat_geodata(data = ., geocolumn = "geo", resolution = "60",output_class = "df", all_regions = TRUE) %>%
# Plot the map
ggplot(data = ., aes(long, lat, group = group)) +
geom_polygon(aes(fill = cat), colour = alpha("white", 1/2), size = .2) +
scale_fill_manual(values = RColorBrewer::brewer.pal(n = 5, name = "Oranges")) +
labs(title = "Disposable household income") +
coord_map(project = "orthographic", xlim = c(-22, 34), ylim = c(35, 70)) +
theme_minimal() +
guides(fill = guide_legend(title = "EUR per Year",title.position = "top", title.hjust = 0))
install.packages("rgdal")
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
# Specify the url that links to the zipped spatial datasets
url = "http://ec.europa.eu/eurostat/cache/GISCO/distribution/v2/nuts/download/ref-nuts-2016-60m.shp.zip"
# Download the file
download.file(url, basename(url))
# Unzip the bulk file
unzip(basename(url))
# Unzip the specific shapefile needed
unzip(paste0(getwd(), "/NUTS_RG_60M_2016_4326_LEVL_2.shp.zip"))
# Read in the shapefile
geodata <- readOGR(dsn = getwd(), layer = "NUTS_RG_60M_2016_4326_LEVL_2")
# to get the version of R used in the notebook
paste("The R Version used in this notebook is", getRversion())
_
# Define the CRAN repository for this session
r_rep = getOption("repos")
r_rep["CRAN"] = "http://cran.us.r-project.org"
options(repos = r_rep)
paste("eurostat Version is:", pkg_used["eurostat", "Version"])
# For every package print the version of the package, the version of R that depends on and the packages that imports
paste("eurostat Version is:", pkg_used["eurostat", "Version"])
# Create a list with all the available packages in my R environment
pkg_used <- available.packages()
# For every package print the version of the package, the version of R that depends on and the packages that imports
paste("eurostat Version is:", pkg_used["eurostat", "Version"])
paste("rvest Version is:", pkg_used["rvest", "Version"])
paste("knitr Version is:", pkg_used["knitr", "Version"])
paste("rgdal Version is:", pkg_used["rgdal", "Version"])
paste("countrycode Version is:", pkg_used["countrycode", "Version"])
paste("dplyr Version is:", pkg_used["dplyr", "Version"])
paste("reshape2 Version is:", pkg_used["reshape2", "Version"])
paste("ggplot2 Version is:", pkg_used["ggplot2", "Version"])
paste("TraMineR Version is:", pkg_used["TraMineR", "Version"])
paste("cluster Version is:", pkg_used["cluster", "Version"])
paste("factoextra Version is:", pkg_used["factoextra", "Version"])
paste("RColorBrewer Version is:", pkg_used["RColorBrewer", "Version"])
paste("leaflet Version is:", pkg_used["leaflet", "Version"])
paste("plotly Version is:", pkg_used["plotly", "Version"])
install.packages("rgdal")
# Read in the shapefile
geodata <- readOGR(dsn = getwd(), layer = "NUTS_RG_60M_2016_4326_LEVL_2")
library(rgdal)
# Read in the shapefile
geodata <- readOGR(dsn = getwd(), layer = "NUTS_RG_60M_2016_4326_LEVL_2")
getwd()
url = "http://ec.europa.eu/eurostat/cache/GISCO/distribution/v2/nuts/download/ref-nuts-2016-60m.shp.zip"
# Download the file
download.file(url, basename(url))
# Unzip the bulk file
unzip(basename(url))
# Unzip the specific shapefile needed
unzip(paste0(getwd(), "/NUTS_RG_60M_2016_4326_LEVL_2.shp.zip"))
# Read in the shapefile
geodata <- readOGR(dsn = getwd(), layer = "NUTS_RG_60M_2016_4326_LEVL_2")
# Unzip the specific shapefile needed
unzip(paste0(getwd(), "/NUTS_RG_60M_2016_4326_LEVL_2.shp.zip"))
getwd()
# Unzip the specific shapefile needed
unzip("D:/LUKA/Academic/HS/NASTAVA/20-21/WebMultiVar/Empirical/NUTS_RG_60M_2016_4326_LEVL_2.shp.zip")
# Unzip the specific shapefile needed
unzip("D:/LUKA/Academic/HS/NASTAVA/20-21/WebMultiVar/Empirical/ref-nuts-2016-60m.shp.zip")
# Read in the shapefile
geodata <- readOGR(dsn = getwd(), layer = "NUTS_RG_60M_2016_4326_LEVL_2")
?readOGR
# Read in the shapefile
geodata <- readOGR(dsn = "D:/LUKA/Academic/HS/NASTAVA/20-21/WebMultiVar/Empirical/ref-nuts-2016-60m.shp.zip", layer = "NUTS_RG_60M_2016_4326_LEVL_2")
# Read in the shapefile
geodata <- readOGR(dsn = "D:/LUKA/Academic/HS/NASTAVA/20-21/WebMultiVar/Empirical", layer = "NUTS_RG_60M_2016_4326_LEVL_2")
# Unzip the specific shapefile needed
proba <- unzip("D:/LUKA/Academic/HS/NASTAVA/20-21/WebMultiVar/Empirical/ref-nuts-2016-60m.shp.zip")
proba
# Unzip the specific shapefile needed
proba <- unzip("../Empirical/ref-nuts-2016-60m.shp.zip")
# Specify the ID of the dataset required
id <- "edat_lfse_22"
# Request of the dataset
young_unempl <- get_eurostat(id, filters = list(lastTimePeriod=11, sex = "T",age = "Y18-24"),
time_format = "num")
young_unempl
# Create a new column for country names
geodata@data$cntr_name <- countrycode(geodata@data$CNTR_CODE, "iso2c", "country.name")
library(countrycode)
# Create a new column for country names
geodata@data$cntr_name <- countrycode(geodata@data$CNTR_CODE, "iso2c", "country.name")
# Read in the shapefile
geodata <- readOGR(dsn = "D:/LUKA/Academic/HS/NASTAVA/20-21/WebMultiVar/Empirical", layer = "NUTS_RG_60M_2016_4326_LEVL_2")
# Read in the shapefile
geodata <- readOGR(dsn = "D:/LUKA/Academic/HS/NASTAVA/20-21/WebMultiVar/Empirical", layer = "NUTS_RG_01M_2021_4326_LEVL_2")
getwd()
# Specify the url that links to the zipped spatial datasets
url = "https://gisco-services.ec.europa.eu/distribution/v2/nuts/download/ref-nuts-2021-60m.shp.zip"
# Download the file
download.file(url, basename(url))
# Unzip the bulk file
unzip(basename(url))
# Unzip the specific shapefile needed
unzip(paste0(getwd(), "/NUTS_RG_60M_2021_4326_LEVL_2.shp.zip"))
# Read in the shapefile
geodata <- readOGR(dsn = getwd(), layer = "NUTS_RG_60M_2021_4326_LEVL_2")
# Create a new column for country names
geodata@data$cntr_name <- countrycode(geodata@data$CNTR_CODE, "iso2c", "country.name")
# Because European commission uses EL for Greece (in ISO 3166-1 alpha-2 codes is GR) and UK for United Kingdom (in ISO 3166-1 alpha-2 codes is GB) I should replace these two countries manually
geodata@data$cntr_name <- ifelse(geodata@data$CNTR_CODE=="EL","Greece", ifelse(geodata@data$CNTR_CODE=="UK", "United Kingdom", geodata@data$cntr_name))
# I change the years from numbers to characters so to be recongised as categorical rather than continuous variable
young_unempl$time <- as.character(young_unempl$time)
# Create a plot by showing the European % average of young people neither in employment nor in education and training
young_unempl %>%
group_by(time) %>%
summarise_all(mean, na.rm = TRUE) %>%
ggplot() +
geom_bar(aes(x = time, y = values), stat = "identity", fill = "coral2") +
labs(title = "European average % of young unemployed people",
x = "Years",
y = "% of young people",
caption = "Data downloaded from Eurostat\ncalculations made by the author") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Create a new column to store the number of characters of the geography
young_unempl$n_char <- nchar(as.character(young_unempl$geo))
# Subset only the NUTS 2 regions - their geography code contains 4 characters
young_unempl_NUTS2 <- young_unempl %>%
filter(n_char == 4)
# Calculate quintiles by year
# It is good to specify  the filter function to be used from dplyr function to avoid error messages
quant_data <- NULL
for (var in unique(young_unempl_NUTS2$time)) {
young_unempl_NUTS2_temp <- young_unempl_NUTS2 %>%
dplyr::filter(time == var) %>%
mutate(quintiles = ntile(values, 5) )
quant_data <- rbind(quant_data,young_unempl_NUTS2_temp)
}
# I delete the column inlcuding the % as I will use the quintiles from now on in the analysis
quant_data <- subset(quant_data, select = -values)
# Re-format the data from long to wide format
# This means that every row will represent a region and every column represents a year
quant_data_wide <-
dcast(quant_data,
sex + age + training + wstatus + unit + geo + n_char ~ time,
value.var = 'quintiles')
library(maditr )
install.packages("maditr")
library(maditr )
# Re-format the data from long to wide format
# This means that every row will represent a region and every column represents a year
quant_data_wide <-
dcast(quant_data,
sex + age + training + wstatus + unit + geo + n_char ~ time,
value.var = 'quintiles')
# We remove rows that  do not have values in at least one year so we have consistency between sequences
quant_data_wide <- na.omit(quant_data_wide)
# Have a look at the dataset
kable(head(quant_data_wide))
library(kableExtra)
# Have a look at the dataset
kable(head(quant_data_wide))
# Create the sequence object using only the quintiles that every region belongs
seq_obj <- seqdef(quant_data_wide[,8:18])
# These are the packages required to run this notebook
# First should be installed
# install.packages("eurostat")
# install.packages("rvest")
# install.packages("knitr")
# install.packages("rgdal")
# install.packages("countrycode")
# install.packages("dplyr")
# install.packages("reshape2")
# install.packages("ggplot2")
# install.packages("TraMineR")
# install.packages("cluster")
# install.packages("factoextra")
# install.packages("RColorBrewer")
# install.packages("leaflet")
# install.packages("plotly")
# And then should be loaded
library(eurostat)
library(rvest)
library(knitr)
library(rgdal)
library(countrycode)
library(dplyr)
library(reshape2)
library(ggplot2)
library(TraMineR)
library(cluster)
library(factoextra)
library(RColorBrewer)
library(leaflet)
library(plotly)
# Calculate the distance matrix
seq.OM <- seqdist(seq_obj, method = "OM", sm = subs_costs)
# Create the sequence object using only the quintiles that every region belongs
seq_obj <- seqdef(quant_data_wide[,8:18])
# Calculate substistution costs
subs_costs <- seqsubm(seq_obj, method = "TRATE")
# Print the substitution costs
kable(subs_costs)
# Calculate the distance matrix
seq.OM <- seqdist(seq_obj, method = "OM", sm = subs_costs)
# Assess different clustering solutions to specify the optimal number of clusters
fviz_nbclust(seq.OM, cluster::pam, method = "wss")
# Assess different clustering solutions to specify the optimal number of clusters
fviz_nbclust(seq.OM, cluster::pam, method = "silhouette")
# Run clustering algorithm with k = 4
pam.res <- pam(seq.OM, 4)
# Assign the cluster group into the tabular dataset
quant_data_wide$cluster <- pam.res$clustering
# Then rename clusters
quant_data_wide$cluster <- factor(quant_data_wide$cluster, levels=c(1, 2, 3, 4),
labels=c("Stable Low youth unemployment",
"Stable Moderate youth unemployment",
"Increasingly High youth unemployment",
"Stable High youth unemployment"))
# Plot of individual sequences split by sequence group
seqIplot(seq_obj, group = quant_data_wide$cluster, ylab = "Number of sequences")
# Distribution plot by sequence group
seqdplot(seq_obj, group = quant_data_wide$cluster, border=NA, ylab = "Distribution of sequences")
# Merge the spatial to the tabular dataset which includes the cluster names
map_data <- merge(geodata, quant_data_wide, by.x="FID", by.y="geo", all.x=TRUE)
# Create a map showing the distribution of sequence clusters
# Specify the colour palette
myColors <- rev(brewer.pal(4,"RdYlGn"))
pal <- colorFactor(myColors, domain = unique(map_data$cluster))
# Create the initial background map, zooming in Europe
colourmap <- leaflet() %>%
addTiles() %>%
setView(lat = 55, lng = 1, zoom = 3)
# Create the interactive map showing the sequence clusters
colourmap %>%
addPolygons(data = map_data,
fillColor = ~pal(cluster),
weight = 0.2,
opacity = 0.8,
color = "white",
dashArray = "3",
fillOpacity = 0.7,
popup = paste("Cluster: ", map_data$cluster, "<br>",
"NUTS 2 Name: ", map_data$NUTS_NAME, "<br>",
"Country Name: ", map_data$cntr_name, "<br>"),
highlight = highlightOptions(
weight = 5,
color = "#666",
dashArray = "",
fillOpacity = 0.7,
bringToFront = TRUE)) %>%
addLegend(pal = pal,
values  = map_data$cluster,
na.label = "Missing data",
position = "bottomleft",
title = "Youth unemployment trajectories by NUTS 2 in Europe")
# Calculate country summary statistics
freq_reg <- map_data@data %>%
group_by(cntr_name, cluster) %>%
summarise(n = n()) %>%
mutate(freq = n / sum(n))
# reformat the data to order them by clusters frequency
data_wide <- dcast(freq_reg, cntr_name ~ cluster, value.var="freq")
data_wide <- data_wide[order(-data_wide$`Stable Low youth unemployment`,
-data_wide$`Stable Moderate youth unemployment`,
-data_wide$`Increasingly High youth unemployment`,
-data_wide$`Stable High youth unemployment`),]
# Create a bar plot for country distribution of clusters
distribution_plot <- ggplot() +
geom_bar(aes(y =  freq, x = cntr_name, fill = cluster), data = freq_reg,  stat="identity")+
labs(title = "Distribution of youth unemployment trajectories across Europe",
x = "Countries", y = "Proportion", fill = "") +
theme_minimal() +
theme(axis.text.x=element_text(angle = 90, hjust = 1)) +
scale_x_discrete(limits=c(data_wide$cntr_name)) +
scale_fill_brewer(palette="RdYlGn", na.value = "grey64", direction = -1)
# Set an interactive mode to the plot
ggplotly(distribution_plot)
rm(list=ls())
# to get the version of R used in the notebook
paste("The R Version used in this notebook is", getRversion())
``{r}
# Define the CRAN repository for this session
r_rep = getOption("repos")
r_rep["CRAN"] = "http://cran.us.r-project.org"
options(repos = r_rep)
# These are the packages required to run this notebook
# First should be installed
# install.packages("eurostat")
# install.packages("rvest")
# install.packages("knitr")
# install.packages("rgdal")
# install.packages("countrycode")
# install.packages("dplyr")
# install.packages("reshape2")
# install.packages("ggplot2")
# install.packages("TraMineR")
# install.packages("cluster")
# install.packages("factoextra")
# install.packages("RColorBrewer")
# install.packages("leaflet")
# install.packages("plotly")
# And then should be loaded
library(eurostat)
library(rvest)
library(knitr)
library(rgdal)
library(countrycode)
library(dplyr)
library(reshape2)
library(ggplot2)
library(TraMineR)
library(cluster)
library(factoextra)
library(RColorBrewer)
library(leaflet)
library(plotly)
# Create a list with all the available packages in my R environment
pkg_used <- available.packages()
# For every package print the version of the package, the version of R that depends on and the packages that imports
paste("eurostat Version is:", pkg_used["eurostat", "Version"])
paste("rvest Version is:", pkg_used["rvest", "Version"])
paste("knitr Version is:", pkg_used["knitr", "Version"])
paste("rgdal Version is:", pkg_used["rgdal", "Version"])
paste("countrycode Version is:", pkg_used["countrycode", "Version"])
paste("dplyr Version is:", pkg_used["dplyr", "Version"])
paste("reshape2 Version is:", pkg_used["reshape2", "Version"])
paste("ggplot2 Version is:", pkg_used["ggplot2", "Version"])
paste("TraMineR Version is:", pkg_used["TraMineR", "Version"])
paste("cluster Version is:", pkg_used["cluster", "Version"])
paste("factoextra Version is:", pkg_used["factoextra", "Version"])
paste("RColorBrewer Version is:", pkg_used["RColorBrewer", "Version"])
paste("leaflet Version is:", pkg_used["leaflet", "Version"])
paste("plotly Version is:", pkg_used["plotly", "Version"])
# search information about the datasets that are related to young unemployed people
kable(head(search_eurostat("Young people neither in employment")))
# Request of the dataset
young_unempl <- get_eurostat(id, filters = list(lastTimePeriod=11, sex = "T",age = "Y18-24"),
time_format = "num")
# Specify the ID of the dataset required
id <- "edat_lfse_22"
# Request of the dataset
young_unempl <- get_eurostat(id, filters = list(lastTimePeriod=11, sex = "T",age = "Y18-24"),
time_format = "num")
View(young_unempl)
# Specify the url that links to the zipped spatial datasets
url = "https://gisco-services.ec.europa.eu/distribution/v2/nuts/download/ref-nuts-2021-60m.shp.zip"
# Download the file
download.file(url, basename(url))
# Unzip the bulk file
unzip(basename(url))
# Unzip the specific shapefile needed
unzip(paste0(getwd(), "/NUTS_RG_60M_2021_4326_LEVL_2.shp.zip"))
# Read in the shapefile
geodata <- readOGR(dsn = getwd(), layer = "NUTS_RG_60M_2021_4326_LEVL_2")
# Create a new column for country names
geodata@data$cntr_name <- countrycode(geodata@data$CNTR_CODE, "iso2c", "country.name")
# Because European commission uses EL for Greece (in ISO 3166-1 alpha-2 codes is GR) and UK for United Kingdom (in ISO 3166-1 alpha-2 codes is GB) I should replace these two countries manually
geodata@data$cntr_name <- ifelse(geodata@data$CNTR_CODE=="EL","Greece", ifelse(geodata@data$CNTR_CODE=="UK", "United Kingdom", geodata@data$cntr_name))
# I change the years from numbers to characters so to be recongised as categorical rather than continuous variable
young_unempl$time <- as.character(young_unempl$time)
# Create a plot by showing the European % average of young people neither in employment nor in education and training
young_unempl %>%
group_by(time) %>%
summarise_all(mean, na.rm = TRUE) %>%
ggplot() +
geom_bar(aes(x = time, y = values), stat = "identity", fill = "coral2") +
labs(title = "European average % of young unemployed people",
x = "Years",
y = "% of young people",
caption = "Data downloaded from Eurostat\ncalculations made by the author") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
